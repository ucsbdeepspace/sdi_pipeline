{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import sep\n",
    "import glob\n",
    "import numpy as np\n",
    "import astropy.units as u\n",
    "import matplotlib.pyplot as plt\n",
    "import astroalign as aa\n",
    "from astropy.io import fits\n",
    "from astropy.stats import SigmaClip\n",
    "from astropy.coordinates import SkyCoord\n",
    "from photutils import CircularAperture\n",
    "from photutils.centroids import centroid_sources\n",
    "from photutils.aperture import aperture_photometry\n",
    "from photutils.background import Background2D, MedianBackground\n",
    "from astropy.wcs.utils import skycoord_to_pixel, pixel_to_skycoord\n",
    "from astropy.coordinates import ICRS, FK5\n",
    "from regions import CirclePixelRegion, PixCoord\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bunch of empty arrays for various things. They all live up here for conveniance. Most are used, some aren't and are leftover from older versions/things I tried.\n",
    "hdus = []\n",
    "aa_images = []\n",
    "\n",
    "idex = []\n",
    "cents = []\n",
    "info = []\n",
    "comb = []\n",
    "masked_ims = []\n",
    "bsims = []\n",
    "residuals = []\n",
    "cpu = []\n",
    "ram = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 0 #counter \n",
    "mask_count = 0 #another counter\n",
    "start = time.time() #time tracker for how long the \"pipeline\" runs.\n",
    "\n",
    "outstr = r\"C:\\Users\\Sam Whitebook\\Documents\\FitsOutput\\Files\\res{}.fits.fz\" #write out string for residuals, edit for your filepath. \n",
    "#IN MY EXTREMELY RIGOUROUS TESTING, I'VE FOUND IT'S BEST TO USE SETS WITH MORE THAN 100 IMAGES.\n",
    "files = sorted(glob.glob(r\"C:\\Users\\Sam Whitebook\\Documents\\Visual Studio 2010\\Projects\\Lubin Lab\\Data\\KOI-5156_IN\\*.fz\")) #science directory, sorted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask(img, srcs, c): #masking function. Takes science image, list of sources (positions), and counter from above. \n",
    "    dat = img\n",
    "    empty_mask = np.zeros([dat.shape[0]+100, dat.shape[1]+100]) # zeros array with the dimensions of the science image +100 pixels. The additional buffer allows masking of edge sources, this is cropped out later\n",
    "    blend_mask = np.ones([dat.shape[0]+100, dat.shape[1]+100]) #ones array with dimensions of science image + 100pixels\n",
    "    \n",
    "    for i, s in enumerate(srcs):\n",
    "        x_cen = s['x']\n",
    "        y_cen = s['y']\n",
    "        radius = ((s['xmax'] - s['xmin'])/2) + 3 #adds a bit to the radius to avoid leaving a halo/fringe on the outer edge\n",
    "        #print(x_cen, y_cen, radius)\n",
    "        center_2 = PixCoord(x_cen+50, y_cen+50)\n",
    "\n",
    "        circle = CirclePixelRegion(center_2, radius) \n",
    "        mask = circle.to_mask() #this and the previous line make a \"circle\" array with ones\n",
    "        app2 = CircularAperture([x_cen , y_cen] , radius) \n",
    "        app_phot2 = aperture_photometry(dat, app2) #aperture sum\n",
    "        blend_val = app_phot2['aperture_sum'][0]/(np.pi*radius**2) #averaging the sum value over the area of the source\n",
    "        empty_mask[mask.bbox.slices] += mask*blend_val #applies each mask times the averaged value to the empty frame\n",
    "        blend_mask[mask.bbox.slices] -= mask #applies the mask to the ones array, essentially leaving negative space where each source is (not actually negative values but negative space in the desgin sense)\n",
    "        \n",
    "    dlt = np.arange(0, 50, 1) #cropping for the zeros array\n",
    "    del1 = np.delete(empty_mask, [i for i in dlt], axis=0)\n",
    "    del2 = np.delete(del1, [i +dat.shape[0] for i in dlt], axis=0)\n",
    "    del3 = np.delete(del2, [i for i in dlt], axis=1)\n",
    "    del4 = np.delete(del3, [i + dat.shape[1] for i in dlt], axis=1)\n",
    "\n",
    "    del1a = np.delete(blend_mask, [i for i in dlt], axis=0) #cropping for the ones array\n",
    "    del2a = np.delete(del1a, [i +dat.shape[0] for i in dlt], axis=0)\n",
    "    del3a = np.delete(del2a, [i for i in dlt], axis=1)\n",
    "    del4a = np.delete(del3a, [i + dat.shape[1] for i in dlt], axis=1)\n",
    "\n",
    "    masked_im = np.multiply(dat, del4a) #applies negative space (blend_mask) to science image, zeroing out the original sources\n",
    "    blended_im  = masked_im + del4 #appalies psf averaged sources back to the original frame.\n",
    "    return blended_im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fit in files: #actual start of code, opens files\n",
    "    hdu = fits.open(fit)\n",
    "    hdus.append(hdu)\n",
    "\n",
    "sigma_clip = SigmaClip(sigma=3.0)\n",
    "bkg_estimator = MedianBackground()\n",
    "aa_images.append((hdus[0])[1].data) #adds first image in set separately since we are aligning everything else to that image; i.e. it doesn't makes sense to align an image to itself. \n",
    "for im in hdus[1:]:#aligns all images in hdus except the first, to the first\n",
    "    aligned = aa.register(im[1].data, (hdus[0])[1].data)[0] #align each image (except the first) to the first image in the set. aa.register returns aligned and footprint [0] index returns aligned\n",
    "    bkg = Background2D(aligned, (50, 50), filter_size=(3, 3), sigma_clip=sigma_clip, bkg_estimator=bkg_estimator)\n",
    "    bkg_median = bkg.background_median\n",
    "    subtracted = aligned - bkg_median\n",
    "    aa_images.append(subtracted)\n",
    "\n",
    "\n",
    "#bkg0 = Background2D(hdus[0][1].data, (50, 50), filter_size=(3, 3), sigma_clip=sigma_clip, bkg_estimator=bkg_estimator)\n",
    "bkg0 = sep.Background((hdus[0])[1].data) #background sub\n",
    "extracted0 = sep.extract((hdus[0])[1].data -bkg0.back(), bkg0.globalrms *3, minarea = 5, segmentation_map = False) #source extractor run since the LCO BANZAI SEP run has weird settings and didn't pick up enough sources\n",
    "\n",
    "tracker = 0 #counter for debugging. \n",
    "for img in aa_images:\n",
    "    masked_ims.append(mask(img, extracted0, c)) #runs each aligned image through masking\n",
    "    #masked_ims.append(img)\n",
    "    #print(tracker)\n",
    "    tracker +=1\n",
    "c = -1 #allows you to run masking differently for the templeate if you want\n",
    "template = np.median(aa_images, axis = 0) #makes template\n",
    "blend_template = mask(template, extracted0, c) #masks template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done in: 2842.7009222507477 seconds\n"
     ]
    }
   ],
   "source": [
    "#just writes out the masked and unmasked templates so they are available to look at\n",
    "temp_out = fits.PrimaryHDU(template) \n",
    "temp_out.writeto(r\"C:\\Users\\Sam Whitebook\\Documents\\FitsOutput\\Templates\\7imgtemplate2.fits\")\n",
    "btemp_out = fits.PrimaryHDU(blend_template)\n",
    "btemp_out.writeto(r\"C:\\Users\\Sam Whitebook\\Documents\\FitsOutput\\Templates\\7imgtemplateblend2.fits\")\n",
    "\n",
    "for msk in masked_ims:\n",
    "    residuals.append(np.subtract(msk, blend_template))\n",
    "    #residuals.append(ois.optimal_system(image=msk, refimage=template, method='Bramich')[0])\n",
    "\n",
    "#another SEP run to pick out sources from the residuals. In theory, these will be a certain set value from the median template and worth doing photometry on.\n",
    "counter = 0\n",
    "for pics in residuals:\n",
    "    bkg = sep.Background(pics)\n",
    "    extracted = sep.extract(pics -bkg.back(), bkg.globalrms *3, minarea = 20, segmentation_map = False)\n",
    "    header = fits.Header([fits.Card(\"History\", \"Extracted by sep\")])\n",
    "    hdul = fits.HDUList([fits.PrimaryHDU(pics), fits.BinTableHDU(data = extracted, header = header, name =\"SEP\", ver  = None)]) \n",
    "    hdul.writeto(outstr.format(counter))\n",
    "    counter += 1\n",
    "\n",
    "end = time.time()\n",
    "elapsed = end - start\n",
    "msg = \"Done in: {} seconds\"\n",
    "print(msg.format(elapsed))\n",
    "#print(mask_count)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2279f055fc79bfa7f36518c703541e0c00c4ba8691d8c0969e7fe2aaddd10293"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
